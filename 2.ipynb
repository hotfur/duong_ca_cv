{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import kornia as K\n",
    "import yaml\n",
    "\n",
    "# Global constant\n",
    "color_distance_threshold = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "skip_frames = 3\n",
    "learning_rate = 0.2\n",
    "pixel_to_mm = 3.285521454\n",
    "robot_height = 215\n",
    "robot_wide = 300\n",
    "# Line color\n",
    "line_color = (255, 0, 0)\n",
    "direction_line_color = (100, 0, 255)\n",
    "text_location1 = (50, 130)\n",
    "text_location2 = (50, 160)\n",
    "text_location3 = (50, 190)\n",
    "text_location4 = (50, 230)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "err = 0.0001\n",
    "# Camera matrix\n",
    "yaml_file = \"cam3.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    with open(yaml_file, \"r\") as f:\n",
    "        data = yaml.load(f, Loader = yaml.loader.SafeLoader)\n",
    "        mtx=np.array(data['camera_matrix'])\n",
    "        dist=np.array(data['dist_coeff'])\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    # Refining the camera matrix using parameters obtained by calibration\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    # Method 1 to undistort the image\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # # Method 2 to undistort the image\n",
    "    # mapx, mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "    # dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "    return dst\n",
    "\n",
    "\n",
    "def find_ax_by_c(x1, y1, x2, y2):\n",
    "    a = (y1 - y2) / (x1 - x2 + err)\n",
    "    b = y1 - x1 * a\n",
    "    return a, b\n",
    "\n",
    "def calc_distance(pixel):\n",
    "    return np.sqrt(robot_wide**2 + robot_height**2 + (pixel*pixel_to_mm)**2)\n",
    "\n",
    "def find_mid_dis(a_mid, b_mid, y_lower):\n",
    "    y = 640\n",
    "    x = (y-b_mid)/(a_mid + err)\n",
    "    if x < 720 and x > 0:\n",
    "        return y_lower*(robot_wide/np.abs(720-x) + 1)\n",
    "    elif x < 0:\n",
    "        return y_lower*(robot_wide/np.abs(720+x) + 1)\n",
    "    else:\n",
    "        return y_lower*(robot_wide/np.abs(x-720) - 1)\n",
    "\n",
    "def mid_line(left_line, right_line, err=0.0001):\n",
    "    ptl1, ptl2 = left_line[0], left_line[1]\n",
    "    ptr1, ptr2 = right_line[0], right_line[1]\n",
    "\n",
    "    # calculate the center line\n",
    "    a_l, b_l = find_ax_by_c(ptl1[1], ptl1[0], ptl2[1], ptl2[0])\n",
    "    a_r, b_r = find_ax_by_c(ptr1[1], ptr1[0], ptr2[1], ptr2[0])\n",
    "\n",
    "    # get intersect point\n",
    "    x_inter = (b_r - b_l) / (a_l - a_r + err)\n",
    "    y_inter = x_inter * a_l + b_l\n",
    "\n",
    "    # get mid_point left\n",
    "    x_ml = x_inter + 1 / err\n",
    "    y_ml = x_ml * a_l + b_l\n",
    "    d_2 = np.square(y_inter - y_ml) + np.square(x_inter - x_ml)\n",
    "\n",
    "    # get mid_point right\n",
    "    # delta = b^2 - 4ac\n",
    "    a_mr = np.square(a_r) + 1\n",
    "    b_mr = -2 * (x_inter + y_inter * a_r - a_r * b_r)\n",
    "    c_mr = -(d_2 - np.square(x_inter) - np.square(y_inter) + 2 * y_inter * b_r - np.square(b_r))\n",
    "    delta = np.square(b_mr) - 4 * a_mr * c_mr\n",
    "\n",
    "    # get x_mid_right and y_mid_right\n",
    "    x_mr1 = (-b_mr - np.sqrt(delta)) / (2 * a_mr + err)\n",
    "    x_mr2 = (-b_mr + np.sqrt(delta)) / (2 * a_mr + err)\n",
    "\n",
    "    y_mr1 = a_r * x_mr1 + b_r\n",
    "    y_mr2 = a_r * x_mr2 + b_r\n",
    "\n",
    "    # return mid_line\n",
    "    if x_mr1 > x_inter:\n",
    "        x_mid, y_mid = (x_ml + x_mr1) / 2, (y_ml + y_mr1) / 2\n",
    "        a_mid, b_mid = find_ax_by_c(x_mid, y_mid, x_inter, y_inter)\n",
    "    else:\n",
    "        x_mid, y_mid = (x_ml + x_mr2) / 2, (y_ml + y_mr2) / 2\n",
    "        a_mid, b_mid = find_ax_by_c(x_mid, y_mid, x_inter, y_inter)\n",
    "\n",
    "    x_mid_lower = 720\n",
    "    y_mid_lower = a_mid * x_mid_lower + b_mid\n",
    "\n",
    "    x_mid_upper = 0\n",
    "    y_mid_upper = b_mid\n",
    "\n",
    "    return (int(y_mid_lower), int(x_mid_lower)), (int(y_mid_upper), int(x_mid_upper)), (a_mid, b_mid)\n",
    "\n",
    "\n",
    "def lane_making(img):\n",
    "    arr = np.array(img)\n",
    "    arr[:, 0], arr[:, -1] = arr[:, -1], arr[:, 0]\n",
    "    x_rgb = torch.tensor(arr, device=device).unsqueeze(0) / 255\n",
    "    x_rgb = torch.transpose(x_rgb, dim0=0, dim1=-1)[..., 0]\n",
    "    x_rgb = x_rgb.unsqueeze(0)\n",
    "    # Convert to Lab colorspace\n",
    "    img_blurred = K.color.rgb_to_lab(x_rgb)\n",
    "    # Seperate the color components and lightning\n",
    "    lightning = img_blurred[0, 0, :, :]\n",
    "    std_mean_lightning = torch.std_mean(lightning)\n",
    "    color = img_blurred[0, 1:, :, :]\n",
    "    color_dist = torch.sqrt(torch.sum(torch.pow(color, exponent=2), dim=0))\n",
    "    # Apply adaptive thresholding for lightning matrix and global thresholding for color matrix\n",
    "    lightning = lightning > (std_mean_lightning[0] + std_mean_lightning[1])\n",
    "    color_thresh = color_dist < color_distance_threshold\n",
    "    mixture = torch.logical_and(color_thresh, lightning)\n",
    "    thresh_result = torch.where(mixture, 1.0, 0.0)\n",
    "    # Return black and white image to CPU for contour finding\n",
    "    bw = torch.squeeze(thresh_result).cpu().numpy().astype(np.uint8) * 255\n",
    "    contours = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "    # Defensive programming\n",
    "    if len(contours) < 2:\n",
    "        return None\n",
    "    # Filter contours by area and number of vertices\n",
    "    contours_and_weights = []\n",
    "    i = 0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 0:\n",
    "            contours_and_weights.append((area, i, cnt))\n",
    "        i += 1\n",
    "    contours_and_weights.sort(reverse=True)\n",
    "    # Filter contours by area powered by image momentum\n",
    "    contours = []\n",
    "    for cnt in range(min(6, len(contours_and_weights))):\n",
    "        contour = contours_and_weights[cnt][2]\n",
    "        moment = np.power(contours_and_weights[cnt][0], cv2.HuMoments(cv2.moments(contour))[0])\n",
    "        contours.append((moment, cnt, contour))\n",
    "    # Defensive programming\n",
    "    if len(contours) < 2:\n",
    "        return None\n",
    "    lines = []\n",
    "    # Take only the two best contours as line.\n",
    "    contours.sort(reverse=True)\n",
    "    contours = contours[:2]\n",
    "    # Write contours to image\n",
    "    for moment, i, cnt in contours:\n",
    "        rows, cols = img.shape[:2]\n",
    "        [vx, vy, x, y] = cv2.fitLine(cnt, cv2.DIST_L2, 0, 0.01, 0.01)\n",
    "        lefty = int(np.clip((-x * vy / vx) + y, -10000, 10000))\n",
    "        righty = int(np.clip(((cols - x) * vy / vx) + y, -10000, 10000))\n",
    "        lines.append((cols - 1, righty))\n",
    "        lines.append((0, lefty))\n",
    "    return (lines[0], lines[1]), (lines[2], lines[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "cap = cv2.VideoCapture('/home/hoangan/Documents/Code/python_project/spring_22_23/computer_vision/Assignment_1/videos/video2.mp4')\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "# Read until video is completed\n",
    "output = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*'MJPG'), 10, (int(cap.get(3)), int(cap.get(4))))\n",
    "num_frame = 0\n",
    "_left_line, _right_line, _mid_line = ((0,0), (0,0)), ((0,0), (0,0)), ((0,0), (0,0))\n",
    "angle, speed_feedback = 0, 0\n",
    "w, h = int(cap.get(3)), int(cap.get(4))\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if num_frame % 3 == 0:\n",
    "        # Just to prevent overflow\n",
    "        # num_frame = 0\n",
    "        _lanes = lane_making(frame)\n",
    "        if _lanes is not None:\n",
    "            _left_line, _right_line = _lanes\n",
    "            _mid_line = mid_line(_left_line, _right_line)\n",
    "            # distance midline & mid of image\n",
    "            a_mid, b_mid = _mid_line[2]\n",
    "            y_lower = 1280/2 - _mid_line[0][0]\n",
    "            dis_mid = find_mid_dis(a_mid, b_mid, y_lower)\n",
    "\n",
    "            camera_axis_to_mid = np.clip(w // 2 - _mid_line[0][0], -w // 2, w // 2)\n",
    "            angle = (angle + learning_rate * np.clip(a_mid, -np.pi/4, np.pi/4)) / (1 + learning_rate)\n",
    "            speed_feedback_raw = np.clip(0.5 - _mid_line[1][0]/w, -0.5, 0.5)\n",
    "            speed_feedback = (speed_feedback + learning_rate * abs(1 + np.exp(-speed_feedback_raw))) / (1 + learning_rate)\n",
    "    num_frame += 1\n",
    "    cv2.line(frame, _left_line[0], _left_line[1], line_color, 3)\n",
    "    cv2.line(frame, _right_line[0], _right_line[1], line_color, 3)\n",
    "    cv2.line(frame, _mid_line[0], _mid_line[1], direction_line_color, 3)\n",
    "    cv2.putText(frame, 'speed_feedback: ' + str(round(speed_feedback, 3)), text_location1, font, 1, line_color, 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, 'angle: ' + str(round(np.rad2deg(angle), 3)), text_location2, font, 1, line_color, 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, 'camera_axis_to_mid: ' + str(camera_axis_to_mid), text_location3, font, 1, line_color, 1, cv2.LINE_AA)\n",
    "    #cv2.putText(frame, 'camera_axis_to_mid: ' + str(round(calc_distance(camera_axis_to_mid), 3)), text_location4, font, 1, line_color, 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, 'dis_mid: ' + str(round(dis_mid, 3)), text_location4, font, 1, line_color, 1, cv2.LINE_AA)\n",
    "    cv2.circle(frame, (w//2, h), 5, direction_line_color, -1)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    if not ret:\n",
    "        break\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('p'):\n",
    "        cv2.waitKey(-1) #wait until any key is pressed\n",
    "\n",
    "# When everything done, release the video capture object & Closes all the frames\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
