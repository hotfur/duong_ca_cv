{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import kornia as K\n",
    "# Global constant\n",
    "color_distance_threshold = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Line color\n",
    "line_color = (255,100,0)\n",
    "direction_line_color = (100,0,255)\n",
    "text_location = (50,100)\n",
    "err = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ax_by_c(x1, y1, x2, y2):\n",
    "    a = (y1-y2)/(x1-x2+err)\n",
    "    b = y1 - x1 * a\n",
    "    return a, b\n",
    "\n",
    "def mid_line(left_line, right_line, err = 0.0001):\n",
    "    ptl1, ptl2 = left_line[0], left_line[1]\n",
    "    ptr1, ptr2 = right_line[0], right_line[1]\n",
    "\n",
    "    #calculate the center line\n",
    "    a_l, b_l = find_ax_by_c(ptl1[1], ptl1[0], ptl2[1], ptl2[0])\n",
    "    a_r, b_r = find_ax_by_c(ptr1[1], ptr1[0], ptr2[1], ptr2[0])\n",
    "\n",
    "    #get intersect point\n",
    "    x_inter = (b_r-b_l)/(a_l-a_r+err)\n",
    "    y_inter = x_inter*a_l + b_l\n",
    "\n",
    "    #get mid_point left\n",
    "    x_ml = x_inter + 1/err\n",
    "    y_ml = x_ml * a_l + b_l\n",
    "    d_2 = np.square(y_inter - y_ml) + np.square(x_inter - x_ml)\n",
    "\n",
    "    #get mid_point right\n",
    "    #delta = b^2 - 4ac\n",
    "    a_mr = np.square(a_r) + 1\n",
    "    b_mr = -2*(x_inter+y_inter*a_r-a_r*b_r)\n",
    "    c_mr = -(d_2 - np.square(x_inter) - np.square(y_inter) + 2*y_inter*b_r - np.square(b_r))\n",
    "    delta = np.square(b_mr) - 4*a_mr*c_mr\n",
    "\n",
    "    #get x_mid_right and y_mid_right\n",
    "    x_mr1 = (-b_mr - np.sqrt(delta)) / (2*a_mr+err)\n",
    "    x_mr2 = (-b_mr + np.sqrt(delta)) / (2*a_mr+err)\n",
    "\n",
    "    y_mr1 = a_r * x_mr1 + b_r\n",
    "    y_mr2 = a_r * x_mr2 + b_r\n",
    "\n",
    "    #return mid_line\n",
    "    if x_mr1  > x_inter:\n",
    "        x_mid, y_mid = (x_ml + x_mr1)/2, (y_ml + y_mr1)/2\n",
    "        a_mid, b_mid = find_ax_by_c(x_mid, y_mid, x_inter, y_inter)\n",
    "    else:\n",
    "        x_mid, y_mid = (x_ml + x_mr2)/2, (y_ml + y_mr2)/2\n",
    "        a_mid, b_mid = find_ax_by_c(x_mid, y_mid, x_inter, y_inter)\n",
    "    \n",
    "    x_mid_lower = 720\n",
    "    y_mid_lower = a_mid * x_mid_lower + b_mid\n",
    "\n",
    "    x_mid_upper = 0\n",
    "    y_mid_upper = b_mid\n",
    "        \n",
    "    return ((int(y_mid_lower), int(x_mid_lower)), (int(y_mid_upper), int(x_mid_upper)), (a_mid, b_mid))\n",
    "\n",
    "\n",
    "def lane_making(img):\n",
    "    arr = np.array(img)\n",
    "    arr[:, 0], arr[:, -1] = arr[:, -1], arr[:, 0]\n",
    "    x_rgb = torch.tensor(arr, device=device).unsqueeze(0) / 255\n",
    "    x_rgb = torch.transpose(x_rgb, dim0=0, dim1=-1)[..., 0]\n",
    "    x_rgb = x_rgb.unsqueeze(0)\n",
    "    # Convert to Lab colorspace\n",
    "    img_blurred = K.color.rgb_to_lab(x_rgb)\n",
    "    # Seperate the color components and lightning\n",
    "    lightning = img_blurred[0, 0, :, :]\n",
    "    std_mean_lightning = torch.std_mean(lightning)\n",
    "    color = img_blurred[0, 1:, :, :]\n",
    "    color_dist = torch.sqrt(torch.sum(torch.pow(color, exponent=2), dim=0))\n",
    "    # Apply adaptive thresholding for lightning matrix and global thresholding for color matrix\n",
    "    lightning = lightning > (std_mean_lightning[0] + std_mean_lightning[1])\n",
    "    color_thresh = color_dist < color_distance_threshold\n",
    "    mixture = torch.logical_and(color_thresh, lightning)\n",
    "    thresh_result = torch.where(mixture, 1.0, 0.0)\n",
    "    # Return black and white image to CPU for contour finding\n",
    "    bw = torch.squeeze(thresh_result).cpu().numpy().astype(np.uint8) * 255\n",
    "    contours = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "    # Defensive programming\n",
    "    if len(contours) == 0:\n",
    "        return\n",
    "    # Filter contours by area and number of vertices\n",
    "    contours_and_weights = []\n",
    "    i = 0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 0:\n",
    "            contours_and_weights.append((area, i, cnt))\n",
    "        i += 1\n",
    "    contours_and_weights.sort(reverse=True)\n",
    "    # Filter contours by area powered by image momentum\n",
    "    contours = []\n",
    "    for cnt in range(min(6, len(contours_and_weights))):\n",
    "        contour = contours_and_weights[cnt][2]\n",
    "        moment = np.power(contours_and_weights[cnt][0], cv2.HuMoments(cv2.moments(contour))[0])\n",
    "        contours.append((moment, cnt, contour))\n",
    "    # Defensive programming\n",
    "    if len(contours) == 0:\n",
    "        return\n",
    "    lines = []\n",
    "    # Take only the two best contours as line.\n",
    "    contours.sort(reverse=True)\n",
    "    contours = contours[:2]\n",
    "    # Write contours to image\n",
    "    for moment, i, cnt in contours:\n",
    "        rows, cols = img.shape[:2]\n",
    "        [vx, vy, x, y] = cv2.fitLine(cnt, cv2.DIST_L2, 0, 0.01, 0.01)\n",
    "        lefty = int(np.clip((-x * vy / vx) + y, -10000, 10000))\n",
    "        righty = int(np.clip(((cols - x) * vy / vx) + y, -10000, 10000))\n",
    "        lines.append((cols - 1, righty))\n",
    "        lines.append((0, lefty))\n",
    "        #cv2.line(img, (cols - 1, righty), (0, lefty), line_color, 2)\n",
    "        \n",
    "    return (lines[0], lines[1]), (lines[2], lines[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "cap = cv2.VideoCapture('/home/hoangan/Documents/Code/python_project/spring_22_23/computer_vision/Assignment_1/videos/video2.mp4')\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "# Read until video is completed\n",
    "output = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*'MJPG'), 10, (int(cap.get(3)), int(cap.get(4))))\n",
    "num_frame = 0\n",
    "_left_line, _right_line, _mid_line = ((0,0), (0,0)), ((0,0), (0,0)), ((0,0), (0,0))\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if num_frame % 3 == 0:\n",
    "        _left_line, _right_line = lane_making(frame)\n",
    "        _mid_line = mid_line(_left_line, _right_line)\n",
    "\n",
    "        #distance midline & mid of image\n",
    "        a_mid, b_mid = _mid_line[2]\n",
    "        distance_mid_lower = 1280/2 - _mid_line[1][0]\n",
    "        distance_mid_upper = 1280/2 - _mid_line[0][0]\n",
    "    \n",
    "\n",
    "    cv2.line(frame, _left_line[0], _left_line[1], line_color, 3)\n",
    "    cv2.line(frame, _right_line[0], _right_line[1], line_color, 3)\n",
    "    cv2.line(frame, _mid_line[0], _mid_line[1], direction_line_color, 3)\n",
    "    cv2.putText(frame, 'd_lower: '+str(distance_mid_lower), (600, 600), cv2.FONT_HERSHEY_SIMPLEX, 2,[150, 0, 150] ,3 , cv2.LINE_AA)\n",
    "    cv2.putText(frame, 'angle: '+str(np.rad2deg(a_mid)), (600, 400), cv2.FONT_HERSHEY_SIMPLEX, 2,[150, 200, 0] ,3 , cv2.LINE_AA)\n",
    "\n",
    "    cv2.putText(frame, 'd_upper: '+str(distance_mid_upper), (600, 100), cv2.FONT_HERSHEY_SIMPLEX, 2,[0, 200, 150] ,3 , cv2.LINE_AA)\n",
    "\n",
    "    cv2.circle(frame, (640, 0), 15, [0, 200, 150], -1 )\n",
    "    cv2.circle(frame, (640, 720), 15, [150, 0, 150], -1 )\n",
    "    cv2.imshow('frame', frame)\n",
    "    num_frame+=1\n",
    "    if not ret:\n",
    "        break\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('p'):\n",
    "        cv2.waitKey(-1) #wait until any key is pressed\n",
    "# When everything done, release the video capture object & Closes all the frames\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
