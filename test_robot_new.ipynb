{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "# Global constant\n",
    "color_distance_threshold = 8\n",
    "black_threshold = 128\n",
    "morphology_iterations = 3\n",
    "# Line color\n",
    "line_color = (100,0,255)\n",
    "direction_line_color = (255,100,0)\n",
    "text_location = (50,100)\n",
    "err = 0.0001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:28:25.674364Z",
     "end_time": "2023-04-02T17:28:26.956033Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def detect_mid_line(ptl1, ptl2, ptr1, ptr2):\n",
    "    y_l1, x_l1 = ptl1\n",
    "    y_l2, x_l2 = ptl2\n",
    "    y_r1, x_r1 = ptr1\n",
    "    y_r2, x_r2 = ptr2\n",
    "\n",
    "    #calculate the center line\n",
    "    a_l, a_r = (y_l1-y_l2)/(x_l1-x_l2+err), (y_r1-y_r2)/(x_r1-x_r2+err)\n",
    "    b_l, b_r = y_l1 - x_l1 * a_l, y_r1 - x_r1 * a_r\n",
    "\n",
    "    #get intersect point\n",
    "    x_inter = (b_r-b_l)/(a_l-a_r+err)\n",
    "    y_inter = x_inter*a_l + b_l\n",
    "\n",
    "    #get mid_point left\n",
    "    x_ml = x_inter + 1/err\n",
    "    y_ml = x_ml * a_l + b_l\n",
    "    d_2 = np.square(y_inter - y_ml) + np.square(x_inter - x_ml)\n",
    "\n",
    "    #get mid_point right\n",
    "    #delta = b^2 - 4ac\n",
    "    a_mr = np.square(a_r) + 1\n",
    "    b_mr = -2*(x_inter+y_inter*a_r-a_r*b_r)\n",
    "    c_mr = -(d_2 - np.square(x_inter) - np.square(y_inter) + 2*y_inter*b_r - np.square(b_r))\n",
    "    delta = np.square(b_mr) - 4*a_mr*c_mr\n",
    "\n",
    "    #get x_mid_right and y_mid_right\n",
    "    x_mr1 = (-b_mr - np.sqrt(delta)) / (2*a_mr+err)\n",
    "    x_mr2 = (-b_mr + np.sqrt(delta)) / (2*a_mr+err)\n",
    "\n",
    "    y_mr1 = a_r * x_mr1 + b_r\n",
    "    y_mr2 = a_r * x_mr2 + b_r\n",
    "\n",
    "    #return mid_line\n",
    "    if x_mr1 > x_inter:\n",
    "        x_mid, y_mid = (x_ml + x_mr1)/2, (y_ml + y_mr1)/2\n",
    "    else:\n",
    "        x_mid, y_mid = (x_ml + x_mr2)/2, (y_ml + y_mr2)/2\n",
    "    return int(y_inter), int(x_inter), int(y_mid), int(x_mid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:28:26.964300Z",
     "end_time": "2023-04-02T17:28:27.005085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def lane_making(img):\n",
    "    # Gaussian filter to slightly reduce noise\n",
    "    img_blurred = cv2.GaussianBlur(img, ksize=(3,3), sigmaX=1, sigmaY=1)\n",
    "    # Convert to Lab\n",
    "    img_blurred = cv2.cvtColor(img_blurred, cv2.COLOR_BGR2Lab)\n",
    "    # Seperate the color components and lightning\n",
    "    lightning = img_blurred[:, :, 0]\n",
    "    mean_lightning = np.mean(lightning)\n",
    "    color = img_blurred[:, :, 1:] - 127\n",
    "    color_dist = np.sqrt(np.sum(color.__pow__(2), axis=2))\n",
    "    # Apply adaptive thresholding for lightning matrix and global thresholding for color matrix\n",
    "    # We must filter black pixel before feeding to otsu\n",
    "    lightning = np.where(lightning>black_threshold, lightning, int(mean_lightning))\n",
    "    _, lightning_thresh = cv2.threshold(lightning, 0, 255, cv2.THRESH_OTSU)\n",
    "    color_thresh = color_dist < color_distance_threshold\n",
    "    mixture = np.logical_and(color_thresh, lightning_thresh.astype(bool))\n",
    "    thresh_result = np.where(mixture, 255, 0).astype(np.int16)\n",
    "    # Apply morphology transformation to filter noises\n",
    "    morph = cv2.dilate(thresh_result, kernel=(3,3), iterations=morphology_iterations)\n",
    "    morph = cv2.erode(morph, kernel=(3,3), iterations=morphology_iterations)\n",
    "    # Apply median filter to remove excessive noises\n",
    "    bw = cv2.medianBlur(morph, ksize=5)\n",
    "    # Applying the Canny Edge filter\n",
    "    edges = cv2.Canny(np.uint8(bw), 0, 255)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 90, 50, None, 0, 0)\n",
    "    if lines is not None:\n",
    "        len_line = len(lines)\n",
    "        if len_line > 3:\n",
    "            get_min = False\n",
    "            get_max = False\n",
    "            #draw lines\n",
    "            min_pt = [len(img[0]), 0, 0]\n",
    "            max_pt = [0, 0, 0]\n",
    "            #get 2 main lines\n",
    "            for i in range(0, len(lines)):\n",
    "                rho, theta = lines[i][0][0], lines[i][0][1]\n",
    "                a, b = math.cos(theta), math.sin(theta)\n",
    "                x0, y0 = a * rho, b * rho\n",
    "                pt1, pt2 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a))), (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "\n",
    "                if abs(pt1[1]-pt2[1]) > 30:\n",
    "                    if min_pt[0] > rho:\n",
    "                        min_pt[0], min_pt[1], min_pt[2]  = x0, pt1, pt2\n",
    "                        get_min = True\n",
    "                    if max_pt[0] < rho:\n",
    "                        max_pt[0], max_pt[1], max_pt[2]  = x0, pt1, pt2\n",
    "                        get_max = True\n",
    "                else:\n",
    "                    len_line -= 1\n",
    "            #get center line\n",
    "            if len_line > 2 and get_min and get_max:\n",
    "                #get center\n",
    "                center = detect_mid_line(min_pt[1], min_pt[2], max_pt[1], max_pt[2])\n",
    "                x_inter, y_inter = center[1], center[0]\n",
    "                # a_mid, b_mid = center[4], center[5]\n",
    "                if x_inter < 0.5 * len(img):\n",
    "                    cv2.line(img, min_pt[1], min_pt[2], line_color, 3, cv2.LINE_AA)\n",
    "                    cv2.line(img, max_pt[1], max_pt[2], line_color, 3, cv2.LINE_AA)\n",
    "                    cv2.line(img, (y_inter, x_inter), (center[2], center[3]), direction_line_color, 3, cv2.LINE_AA)\n",
    "                    cv2.imshow('Frame', img)\n",
    "                    return\n",
    "\n",
    "    cv2.putText(img, 'None', text_location, cv2.FONT_HERSHEY_SIMPLEX, 1, line_color, 2)\n",
    "    cv2.imshow('Frame', img)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:28:27.005138Z",
     "end_time": "2023-04-02T17:28:27.006804Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "cap = cv2.VideoCapture('../../data/line_trace/congthanh_solution.mp4')\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "# Read until video is completed\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "    lane_making(frame)\n",
    "# When everything done, release the video capture object & Closes all the frames\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:30:36.823177Z",
     "end_time": "2023-04-02T17:30:46.412904Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
